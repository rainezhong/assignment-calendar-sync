#!/usr/bin/env python3
"""
Academic Performance Analytics & Health Tracking
Teaching concepts: Time Series Analytics, Trend Detection, Anomaly Detection, Data Visualization
"""

import json
import sqlite3
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field, asdict
from datetime import datetime, timedelta
from pathlib import Path
import logging
from collections import defaultdict, Counter
import statistics
from enum import Enum

logger = logging.getLogger(__name__)

# LEARNING CONCEPT 1: Academic Health Scoring
# Multi-dimensional assessment of student wellbeing and performance

class AcademicHealthStatus(Enum):
    """Overall academic health classification"""
    EXCELLENT = "excellent"      # Everything on track, high performance
    GOOD = "good"               # Mostly on track, some minor issues
    AT_RISK = "at_risk"         # Warning signs present
    CRITICAL = "critical"       # Immediate intervention needed

class StressLevel(Enum):
    """Workload stress classification"""
    LOW = "low"
    MODERATE = "moderate"
    HIGH = "high"
    OVERWHELMING = "overwhelming"

@dataclass
class AcademicHealthMetrics:
    """
    Comprehensive academic health assessment

    Teaching Concepts:
    - Multi-dimensional health scoring
    - Leading vs lagging indicators
    - Actionable insights generation
    """
    overall_status: AcademicHealthStatus

    # Core metrics
    assignment_completion_rate: float  # 0-1
    on_time_submission_rate: float    # 0-1
    average_grade: Optional[float]    # 0-100
    current_stress_level: StressLevel

    # Trend indicators
    grade_trend: str  # improving, stable, declining
    workload_trend: str  # increasing, stable, decreasing
    productivity_trend: str  # improving, stable, declining

    # Risk indicators
    upcoming_deadline_count: int
    overdue_assignments: int
    consecutive_late_submissions: int
    days_since_last_completion: int

    # Positive indicators
    streak_days: int  # Days with consistent progress
    ahead_of_schedule_count: int

    # Analysis metadata
    data_points_analyzed: int
    confidence_score: float
    generated_at: datetime = field(default_factory=datetime.now)

    def to_dict(self) -> Dict[str, Any]:
        """Convert to dictionary for serialization"""
        result = asdict(self)
        result['overall_status'] = self.overall_status.value
        result['current_stress_level'] = self.current_stress_level.value
        result['generated_at'] = self.generated_at.isoformat()
        return result

@dataclass
class SubmissionPattern:
    """
    Analysis of submission timing patterns

    Teaching Concepts:
    - Behavioral pattern recognition
    - Distribution analysis
    - Outlier detection
    """
    average_days_before_deadline: float
    median_days_before_deadline: float
    std_deviation: float

    # Distribution
    early_submissions: int  # > 1 day before
    on_time_submissions: int  # Day of deadline
    late_submissions: int

    # Patterns
    typical_submission_hour: int  # 0-23
    weekend_vs_weekday_ratio: float
    last_minute_tendency: float  # 0-1 (higher = more last minute)

    # Quality correlation
    early_submission_avg_grade: Optional[float] = None
    late_submission_avg_grade: Optional[float] = None

@dataclass
class ProductivityPattern:
    """
    Analysis of productivity patterns

    Teaching Concepts:
    - Time-based productivity analysis
    - Peak performance detection
    - Energy management insights
    """
    peak_productivity_hours: List[int]  # Hours of day (0-23)
    peak_productivity_days: List[int]   # Days of week (0-6)

    # Session patterns
    average_session_length: timedelta
    typical_break_frequency: timedelta
    focus_time_ratio: float  # Actual work / time spent

    # Efficiency trends
    tasks_completed_per_hour: float
    distraction_rate: float  # 0-1

@dataclass
class GradeTrend:
    """
    Grade progression analysis

    Teaching Concepts:
    - Regression analysis
    - Trend detection
    - Forecasting
    """
    current_average: float
    previous_period_average: float
    trend_direction: str  # improving, stable, declining
    trend_strength: float  # 0-1

    # By course
    course_performance: Dict[str, float]  # course -> average
    best_performing_courses: List[str]
    struggling_courses: List[str]

    # Predictions
    projected_end_of_term_gpa: Optional[float] = None
    confidence_interval: Tuple[float, float] = (0.0, 0.0)

# LEARNING CONCEPT 2: Time Series Database Design for Analytics
# Efficient storage and querying of temporal data

class PerformanceDatabase:
    """
    Time series database for performance tracking

    Teaching Concepts:
    - Time series schema design
    - Efficient temporal queries
    - Aggregation strategies
    """

    def __init__(self, storage_dir: Path):
        self.storage_dir = storage_dir
        self.storage_dir.mkdir(parents=True, exist_ok=True)
        self.db = self._init_database()

    def _init_database(self) -> sqlite3.Connection:
        """Initialize performance tracking database"""
        db_path = self.storage_dir / "performance_analytics.db"
        conn = sqlite3.connect(str(db_path))

        # Assignment outcomes table
        conn.execute("""
            CREATE TABLE IF NOT EXISTS assignment_outcomes (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                assignment_id TEXT UNIQUE NOT NULL,
                title TEXT,
                course TEXT,
                assignment_type TEXT,

                -- Timing
                assigned_date DATETIME,
                due_date DATETIME NOT NULL,
                submitted_date DATETIME,
                days_before_deadline REAL,

                -- Performance
                grade REAL,
                points_possible REAL,
                percentage REAL,

                -- Metadata
                difficulty TEXT,
                estimated_hours REAL,
                actual_hours REAL,

                -- Timestamps
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

                -- Indexes
                INDEX idx_course (course),
                INDEX idx_due_date (due_date),
                INDEX idx_submitted_date (submitted_date)
            )
        """)

        # Study sessions table
        conn.execute("""
            CREATE TABLE IF NOT EXISTS study_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_id TEXT UNIQUE NOT NULL,
                assignment_id TEXT,
                course TEXT,

                -- Session details
                start_time DATETIME NOT NULL,
                end_time DATETIME NOT NULL,
                duration_minutes REAL,

                -- Productivity
                tasks_completed INTEGER,
                productivity_score REAL,  -- 0-1
                focus_quality REAL,  -- 0-1

                -- Context
                location TEXT,
                time_of_day TEXT,  -- morning, afternoon, evening, night

                created_at DATETIME DEFAULT CURRENT_TIMESTAMP,

                INDEX idx_start_time (start_time),
                INDEX idx_course (course)
            )
        """)

        # Stress indicators table
        conn.execute("""
            CREATE TABLE IF NOT EXISTS stress_indicators (
                id INTEGER PRIMARY KEY AUTOINCREMENT,

                -- Objective indicators
                concurrent_assignments INTEGER,
                total_hours_required REAL,
                days_until_nearest_deadline REAL,

                -- Derived stress score
                stress_score REAL,  -- 0-1
                stress_level TEXT,

                recorded_at DATETIME DEFAULT CURRENT_TIMESTAMP,

                INDEX idx_recorded_at (recorded_at)
            )
        """)

        # Daily summary table (for efficient querying)
        conn.execute("""
            CREATE TABLE IF NOT EXISTS daily_summaries (
                date DATE PRIMARY KEY,

                assignments_completed INTEGER DEFAULT 0,
                assignments_started INTEGER DEFAULT 0,
                study_minutes INTEGER DEFAULT 0,
                average_productivity REAL,

                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        """)

        conn.commit()
        return conn

    def record_assignment_outcome(self, outcome: Dict[str, Any]):
        """Record assignment completion outcome"""
        try:
            # Calculate derived fields
            days_before = None
            if outcome.get('submitted_date') and outcome.get('due_date'):
                delta = outcome['due_date'] - outcome['submitted_date']
                days_before = delta.total_seconds() / (24 * 3600)

            percentage = None
            if outcome.get('grade') and outcome.get('points_possible'):
                percentage = (outcome['grade'] / outcome['points_possible']) * 100

            self.db.execute("""
                INSERT OR REPLACE INTO assignment_outcomes
                (assignment_id, title, course, assignment_type, assigned_date, due_date,
                 submitted_date, days_before_deadline, grade, points_possible, percentage,
                 difficulty, estimated_hours, actual_hours)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                outcome.get('assignment_id'),
                outcome.get('title'),
                outcome.get('course'),
                outcome.get('assignment_type'),
                outcome.get('assigned_date'),
                outcome.get('due_date'),
                outcome.get('submitted_date'),
                days_before,
                outcome.get('grade'),
                outcome.get('points_possible'),
                percentage,
                outcome.get('difficulty'),
                outcome.get('estimated_hours'),
                outcome.get('actual_hours')
            ))
            self.db.commit()

        except Exception as e:
            logger.error(f"Failed to record assignment outcome: {e}")

    def record_study_session(self, session: Dict[str, Any]):
        """Record study session"""
        try:
            start = session['start_time']
            end = session['end_time']
            duration_minutes = (end - start).total_seconds() / 60

            # Determine time of day
            hour = start.hour
            if 5 <= hour < 12:
                time_of_day = "morning"
            elif 12 <= hour < 17:
                time_of_day = "afternoon"
            elif 17 <= hour < 22:
                time_of_day = "evening"
            else:
                time_of_day = "night"

            self.db.execute("""
                INSERT INTO study_sessions
                (session_id, assignment_id, course, start_time, end_time, duration_minutes,
                 tasks_completed, productivity_score, focus_quality, location, time_of_day)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                session.get('session_id'),
                session.get('assignment_id'),
                session.get('course'),
                start,
                end,
                duration_minutes,
                session.get('tasks_completed', 0),
                session.get('productivity_score', 0.5),
                session.get('focus_quality', 0.5),
                session.get('location'),
                time_of_day
            ))
            self.db.commit()

        except Exception as e:
            logger.error(f"Failed to record study session: {e}")

    def get_recent_outcomes(self, days: int = 30) -> List[Dict[str, Any]]:
        """Get assignment outcomes from last N days"""
        cutoff = datetime.now() - timedelta(days=days)

        cursor = self.db.execute("""
            SELECT *
            FROM assignment_outcomes
            WHERE submitted_date >= ?
            ORDER BY submitted_date DESC
        """, (cutoff,))

        return [dict(row) for row in cursor.fetchall()]

    def get_grade_history(self, course: Optional[str] = None) -> List[Tuple[datetime, float]]:
        """Get grade history over time"""
        if course:
            cursor = self.db.execute("""
                SELECT submitted_date, percentage
                FROM assignment_outcomes
                WHERE course = ?
                AND percentage IS NOT NULL
                ORDER BY submitted_date
            """, (course,))
        else:
            cursor = self.db.execute("""
                SELECT submitted_date, percentage
                FROM assignment_outcomes
                WHERE percentage IS NOT NULL
                ORDER BY submitted_date
            """)

        return [(row[0], row[1]) for row in cursor.fetchall()]

# LEARNING CONCEPT 3: Statistical Analysis for Trend Detection
# Identify patterns and trends in performance data

class PerformanceTrendAnalyzer:
    """
    Statistical analysis of performance trends

    Teaching Concepts:
    - Moving averages
    - Linear regression
    - Anomaly detection
    - Forecasting
    """

    @staticmethod
    def calculate_completion_rate(outcomes: List[Dict]) -> float:
        """
        Calculate assignment completion rate

        LEARNING CONCEPT: Simple but essential metric
        """
        if not outcomes:
            return 1.0  # No data = assume good

        completed = sum(1 for o in outcomes if o.get('submitted_date'))
        return completed / len(outcomes)

    @staticmethod
    def calculate_on_time_rate(outcomes: List[Dict]) -> float:
        """Calculate on-time submission rate"""
        submitted = [o for o in outcomes if o.get('submitted_date')]

        if not submitted:
            return 1.0

        on_time = sum(
            1 for o in submitted
            if o.get('submitted_date') and o.get('due_date')
            and o['submitted_date'] <= o['due_date']
        )

        return on_time / len(submitted)

    @staticmethod
    def analyze_submission_patterns(outcomes: List[Dict]) -> SubmissionPattern:
        """
        Analyze submission timing patterns

        LEARNING CONCEPT: Distribution analysis
        """
        days_before_deadline = []
        early = on_time = late = 0
        submission_hours = []
        weekend_count = weekday_count = 0

        for outcome in outcomes:
            if not outcome.get('submitted_date') or not outcome.get('due_date'):
                continue

            delta = outcome['due_date'] - outcome['submitted_date']
            days_before = delta.total_seconds() / (24 * 3600)
            days_before_deadline.append(days_before)

            # Classify
            if days_before > 1:
                early += 1
            elif days_before >= 0:
                on_time += 1
            else:
                late += 1

            # Time patterns
            submitted = outcome['submitted_date']
            submission_hours.append(submitted.hour)

            if submitted.weekday() >= 5:  # Saturday or Sunday
                weekend_count += 1
            else:
                weekday_count += 1

        # Calculate statistics
        if not days_before_deadline:
            return SubmissionPattern(
                average_days_before_deadline=1.0,
                median_days_before_deadline=1.0,
                std_deviation=0.0,
                early_submissions=0,
                on_time_submissions=0,
                late_submissions=0,
                typical_submission_hour=20,
                weekend_vs_weekday_ratio=0.0,
                last_minute_tendency=0.5
            )

        avg_days = statistics.mean(days_before_deadline)
        median_days = statistics.median(days_before_deadline)
        std_dev = statistics.stdev(days_before_deadline) if len(days_before_deadline) > 1 else 0.0

        # Last minute tendency (1 = very last minute, 0 = very early)
        last_minute_tendency = 1.0 - min(1.0, max(0.0, avg_days / 7.0))

        return SubmissionPattern(
            average_days_before_deadline=avg_days,
            median_days_before_deadline=median_days,
            std_deviation=std_dev,
            early_submissions=early,
            on_time_submissions=on_time,
            late_submissions=late,
            typical_submission_hour=statistics.mode(submission_hours) if submission_hours else 20,
            weekend_vs_weekday_ratio=weekend_count / max(weekday_count, 1),
            last_minute_tendency=last_minute_tendency
        )

    @staticmethod
    def detect_grade_trend(grade_history: List[Tuple[datetime, float]]) -> GradeTrend:
        """
        Detect grade trends using linear regression

        LEARNING CONCEPT: Simple linear regression
        """
        if len(grade_history) < 3:
            return GradeTrend(
                current_average=0.0,
                previous_period_average=0.0,
                trend_direction="stable",
                trend_strength=0.0,
                course_performance={},
                best_performing_courses=[],
                struggling_courses=[]
            )

        # Calculate current average
        recent_grades = [g for _, g in grade_history[-10:]]
        current_avg = statistics.mean(recent_grades)

        # Calculate previous period average
        if len(grade_history) > 10:
            previous_grades = [g for _, g in grade_history[-20:-10]]
            if previous_grades:
                previous_avg = statistics.mean(previous_grades)
            else:
                previous_avg = current_avg
        else:
            previous_avg = current_avg

        # Simple trend detection
        grade_diff = current_avg - previous_avg

        if grade_diff > 2:
            trend_direction = "improving"
            trend_strength = min(1.0, abs(grade_diff) / 10.0)
        elif grade_diff < -2:
            trend_direction = "declining"
            trend_strength = min(1.0, abs(grade_diff) / 10.0)
        else:
            trend_direction = "stable"
            trend_strength = 0.2

        return GradeTrend(
            current_average=current_avg,
            previous_period_average=previous_avg,
            trend_direction=trend_direction,
            trend_strength=trend_strength,
            course_performance={},
            best_performing_courses=[],
            struggling_courses=[]
        )

    @staticmethod
    def calculate_stress_level(upcoming_assignments: int,
                              total_hours_required: float,
                              days_available: float) -> Tuple[StressLevel, float]:
        """
        Calculate stress level from workload

        LEARNING CONCEPT: Multi-factor stress scoring
        """
        # Factor 1: Assignment density
        assignments_per_day = upcoming_assignments / max(days_available, 1)

        # Factor 2: Hours per day required
        hours_per_day = total_hours_required / max(days_available, 1)

        # Stress score (0-1)
        stress_score = 0.0

        # More than 2 assignments/day = high stress
        stress_score += min(1.0, assignments_per_day / 2.0) * 0.4

        # More than 8 hours/day = high stress
        stress_score += min(1.0, hours_per_day / 8.0) * 0.6

        # Classify stress level
        if stress_score < 0.25:
            level = StressLevel.LOW
        elif stress_score < 0.5:
            level = StressLevel.MODERATE
        elif stress_score < 0.75:
            level = StressLevel.HIGH
        else:
            level = StressLevel.OVERWHELMING

        return level, stress_score

# Main Performance Analytics class
class PerformanceAnalytics:
    """
    Complete academic performance analytics system

    Orchestrates:
    - Health metric tracking
    - Trend analysis
    - Pattern recognition
    - Insight generation
    """

    def __init__(self, storage_dir: Path = None):
        if storage_dir is None:
            storage_dir = Path.home() / ".academic_assistant" / "performance_analytics"
        storage_dir.mkdir(parents=True, exist_ok=True)

        self.storage_dir = storage_dir
        self.database = PerformanceDatabase(storage_dir)
        self.trend_analyzer = PerformanceTrendAnalyzer()

    def track_academic_health(self,
                             upcoming_assignments: List[Dict] = None,
                             days_to_analyze: int = 30) -> AcademicHealthMetrics:
        """
        Generate comprehensive academic health report

        This is the main entry point - returns complete health assessment
        """
        logger.info(f"Generating academic health report (last {days_to_analyze} days)")

        # Get recent data
        recent_outcomes = self.database.get_recent_outcomes(days=days_to_analyze)

        # Calculate core metrics
        completion_rate = self.trend_analyzer.calculate_completion_rate(recent_outcomes)
        on_time_rate = self.trend_analyzer.calculate_on_time_rate(recent_outcomes)

        # Calculate average grade
        grades = [o['percentage'] for o in recent_outcomes if o.get('percentage')]
        avg_grade = statistics.mean(grades) if grades else None

        # Analyze submission patterns
        submission_pattern = self.trend_analyzer.analyze_submission_patterns(recent_outcomes)

        # Analyze grade trend
        grade_history = self.database.get_grade_history()
        grade_trend = self.trend_analyzer.detect_grade_trend(grade_history)

        # Calculate stress level
        if upcoming_assignments:
            upcoming_count = len(upcoming_assignments)
            total_hours = sum(a.get('estimated_hours', 5) for a in upcoming_assignments)

            # Days until nearest deadline
            nearest_due = min(
                (a['due_date'] for a in upcoming_assignments if a.get('due_date')),
                default=datetime.now() + timedelta(days=7)
            )
            days_available = (nearest_due - datetime.now()).days

            stress_level, stress_score = self.trend_analyzer.calculate_stress_level(
                upcoming_count,
                total_hours,
                days_available
            )
        else:
            stress_level = StressLevel.LOW
            upcoming_count = 0

        # Count risk indicators
        overdue = sum(1 for o in recent_outcomes
                     if o.get('due_date') and not o.get('submitted_date')
                     and o['due_date'] < datetime.now())

        consecutive_late = self._count_consecutive_late(recent_outcomes)

        # Days since last completion
        if recent_outcomes and recent_outcomes[0].get('submitted_date'):
            days_since_last = (datetime.now() - recent_outcomes[0]['submitted_date']).days
        else:
            days_since_last = 999

        # Determine overall status
        overall_status = self._determine_overall_status(
            completion_rate,
            on_time_rate,
            avg_grade,
            stress_level,
            overdue,
            consecutive_late
        )

        # Create health metrics
        metrics = AcademicHealthMetrics(
            overall_status=overall_status,
            assignment_completion_rate=completion_rate,
            on_time_submission_rate=on_time_rate,
            average_grade=avg_grade,
            current_stress_level=stress_level,
            grade_trend=grade_trend.trend_direction,
            workload_trend="stable",  # Would analyze over time
            productivity_trend="stable",  # Would analyze from study sessions
            upcoming_deadline_count=upcoming_count,
            overdue_assignments=overdue,
            consecutive_late_submissions=consecutive_late,
            days_since_last_completion=days_since_last,
            streak_days=0,  # Would calculate from daily activity
            ahead_of_schedule_count=submission_pattern.early_submissions,
            data_points_analyzed=len(recent_outcomes),
            confidence_score=min(1.0, len(recent_outcomes) / 10.0)
        )

        logger.info(f"Health status: {overall_status.value}")
        return metrics

    def _determine_overall_status(self,
                                  completion_rate: float,
                                  on_time_rate: float,
                                  avg_grade: Optional[float],
                                  stress: StressLevel,
                                  overdue: int,
                                  consecutive_late: int) -> AcademicHealthStatus:
        """
        Determine overall health status from metrics

        LEARNING CONCEPT: Rule-based classification with thresholds
        """
        # Critical conditions (immediate intervention needed)
        if overdue >= 3:
            return AcademicHealthStatus.CRITICAL
        if completion_rate < 0.5:
            return AcademicHealthStatus.CRITICAL
        if consecutive_late >= 4:
            return AcademicHealthStatus.CRITICAL
        if stress == StressLevel.OVERWHELMING:
            return AcademicHealthStatus.CRITICAL

        # At-risk conditions (warning signs)
        if overdue >= 1:
            return AcademicHealthStatus.AT_RISK
        if completion_rate < 0.75:
            return AcademicHealthStatus.AT_RISK
        if on_time_rate < 0.7:
            return AcademicHealthStatus.AT_RISK
        if stress == StressLevel.HIGH:
            return AcademicHealthStatus.AT_RISK
        if avg_grade and avg_grade < 70:
            return AcademicHealthStatus.AT_RISK

        # Good conditions
        if completion_rate >= 0.85 and on_time_rate >= 0.80:
            if not avg_grade or avg_grade >= 85:
                return AcademicHealthStatus.EXCELLENT
            else:
                return AcademicHealthStatus.GOOD

        # Default to good
        return AcademicHealthStatus.GOOD

    def _count_consecutive_late(self, outcomes: List[Dict]) -> int:
        """Count consecutive late submissions"""
        consecutive = 0
        max_consecutive = 0

        for outcome in sorted(outcomes, key=lambda o: o.get('submitted_date') or datetime.min):
            if not outcome.get('submitted_date') or not outcome.get('due_date'):
                continue

            if outcome['submitted_date'] > outcome['due_date']:
                consecutive += 1
                max_consecutive = max(max_consecutive, consecutive)
            else:
                consecutive = 0

        return max_consecutive

    def generate_insights(self, metrics: AcademicHealthMetrics) -> List[str]:
        """
        Generate actionable insights from metrics

        LEARNING CONCEPT: Rule-based insight generation
        """
        insights = []

        # Completion rate insights
        if metrics.assignment_completion_rate < 0.8:
            insights.append(
                f"âš ï¸ Completion rate is {metrics.assignment_completion_rate:.0%}. "
                "Try breaking assignments into smaller tasks."
            )
        elif metrics.assignment_completion_rate >= 0.95:
            insights.append(
                f"âœ… Excellent completion rate ({metrics.assignment_completion_rate:.0%})! Keep it up!"
            )

        # On-time submission insights
        if metrics.on_time_submission_rate < 0.7:
            insights.append(
                f"â° Only {metrics.on_time_submission_rate:.0%} of assignments submitted on time. "
                "Consider starting earlier or adjusting time estimates."
            )

        # Grade trend insights
        if metrics.grade_trend == "improving":
            insights.append("ðŸ“ˆ Grades are trending upward - your hard work is paying off!")
        elif metrics.grade_trend == "declining":
            insights.append(
                "ðŸ“‰ Grades are trending downward. Consider visiting office hours or adjusting study strategies."
            )

        # Stress insights
        if metrics.current_stress_level == StressLevel.OVERWHELMING:
            insights.append(
                "ðŸ”¥ Workload is overwhelming. Prioritize ruthlessly and consider extensions if needed."
            )
        elif metrics.current_stress_level == StressLevel.HIGH:
            insights.append(
                "ðŸ˜° High stress detected. Focus on upcoming deadlines and avoid taking on new commitments."
            )

        # Overdue insights
        if metrics.overdue_assignments > 0:
            insights.append(
                f"ðŸš¨ {metrics.overdue_assignments} overdue assignment(s). Tackle these immediately!"
            )

        # Positive reinforcement
        if metrics.ahead_of_schedule_count >= 3:
            insights.append(
                f"ðŸŒŸ {metrics.ahead_of_schedule_count} assignments completed early. Great planning!"
            )

        return insights


# Example usage
if __name__ == "__main__":
    print("ðŸ“Š Academic Performance Analytics")
    print("=" * 60)
    print()
    print("Key Concepts Demonstrated:")
    print("1. Multi-dimensional Health Scoring")
    print("2. Time Series Database Design")
    print("3. Statistical Trend Analysis")
    print("4. Pattern Recognition in Behavior")
    print("5. Anomaly Detection")
    print("6. Actionable Insight Generation")
    print()
    print("This system tracks:")
    print("âœ… Assignment completion rates and patterns")
    print("âœ… Submission timing and trends")
    print("âœ… Grade progression over time")
    print("âœ… Stress indicators and workload")
    print("âœ… Productivity patterns")
    print("âœ… Risk factors and early warnings")
    print("âœ… Positive streaks and achievements")
