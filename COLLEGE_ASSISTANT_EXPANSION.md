# College Student Assistant - Full Feature Expansion

## üéØ Vision: Complete College Life Assistant

Transform from academic tracker ‚Üí **all-in-one college assistant**

---

## üìã Core Feature Categories

### 1. üíº Career & Professional Development (PRIORITY)

#### A. Automated Job/Internship Applications ‚≠ê **YOU NEED THIS**
- Auto-apply to jobs matching your criteria
- Resume parsing and customization per job
- Cover letter generation with AI
- Application tracking and follow-ups
- Interview scheduler

#### B. Resume & Portfolio Builder
- AI-powered resume optimization
- Multiple resume versions for different roles
- ATS (Applicant Tracking System) optimization
- Portfolio website generator
- LinkedIn profile optimization

#### C. Career Guidance
- Career path recommendations based on skills/interests
- Salary insights and negotiation tips
- Company research assistant
- Interview preparation with AI mock interviews
- Networking event finder

### 2. üìö Enhanced Academic Features

#### A. Study Assistant
- AI tutor for homework help
- Study group matcher (connect with classmates)
- Note-taking with auto-summarization
- Flashcard generator from notes
- Practice quiz generator

#### B. Course Planning
- Degree progress tracker
- Course prerequisite mapper
- Schedule optimizer (avoid conflicts, commute time)
- Professor ratings integration (RateMyProfessor)
- Grade predictor based on current performance

#### C. Research Assistant
- Paper finder and summarizer
- Citation manager (auto-format MLA, APA, Chicago)
- Research topic suggester
- Plagiarism checker
- Literature review organizer

### 3. üí∞ Financial Management

#### A. Student Finances
- Budget tracker (dining, books, entertainment)
- Textbook price comparison (buy vs rent vs digital)
- Financial aid deadline tracker
- Student discount finder
- Part-time job earnings tracker

#### B. Scholarship & Grant Finder
- Auto-match with scholarship opportunities
- Application deadline reminders
- Essay requirement tracker
- Financial aid calculator

### 4. üè† Campus Life

#### A. Social & Events
- Campus event calendar
- Club meeting reminders
- Friend availability matcher (free time overlap)
- Study buddy finder
- Campus dining menu + nutrition info

#### B. Housing & Transportation
- Roommate compatibility matcher
- Campus map with class navigation
- Parking spot finder
- Bus/shuttle tracker
- Bike-share integration

### 5. üß† Wellness & Mental Health

#### A. Stress Management
- Stress level tracker
- Meditation timer
- Break reminders
- Sleep schedule optimizer
- Burnout prevention alerts

#### B. Health Tracking
- Fitness goal tracker
- Campus gym class schedule
- Health center appointment booking
- Mental health resource finder
- Crisis hotline quick access

### 6. üì± Communication & Collaboration

#### A. Team Projects
- Group assignment coordinator
- File sharing and version control
- Meeting scheduler (find common free time)
- Task delegator
- Progress tracker per team member

#### B. Professor/TA Communication
- Office hours tracker
- Email templates for professor outreach
- Question queue (track what to ask)
- Grade inquiry templates

---

## üöÄ PRIORITY IMPLEMENTATION: Auto-Apply System

### Feature Overview

**What it does:**
- Scrapes job boards (LinkedIn, Indeed, Handshake, Glassdoor)
- Matches jobs to your profile
- Auto-fills applications
- Submits applications on your behalf
- Tracks all applications
- Sends follow-up reminders

### Technical Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Mobile App                           ‚îÇ
‚îÇ  [Set Preferences] [View Matches] [Track Applications]  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì API calls
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  FastAPI Backend                        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  Job Matcher ‚îÇ  ‚îÇ Auto-Applier ‚îÇ  ‚îÇ   Tracker    ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ               Background Workers (Celery)               ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇJob Scraper   ‚îÇ  ‚îÇForm Filler   ‚îÇ  ‚îÇ Follow-up    ‚îÇ ‚îÇ
‚îÇ  ‚îÇ(Playwright)  ‚îÇ  ‚îÇ(Selenium)    ‚îÇ  ‚îÇ  Scheduler   ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                            ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                External Services                        ‚îÇ
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îÇ
‚îÇ  ‚îÇ  LinkedIn    ‚îÇ  ‚îÇ    Indeed    ‚îÇ  ‚îÇ  Handshake   ‚îÇ ‚îÇ
‚îÇ  ‚îÇ     API      ‚îÇ  ‚îÇ   Scraping   ‚îÇ  ‚îÇ     API      ‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Database Schema Additions

```sql
-- User career profile
CREATE TABLE user_profiles (
    id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(id),

    -- Resume data
    resume_text TEXT,
    resume_pdf_url TEXT,
    skills JSONB,  -- ["Python", "React", "Machine Learning"]
    education JSONB,  -- [{"school": "...", "degree": "...", "gpa": 3.8}]
    experience JSONB,  -- [{"company": "...", "role": "...", "duration": "..."}]

    -- Job preferences
    desired_roles JSONB,  -- ["Software Engineer", "Data Analyst"]
    desired_locations JSONB,  -- ["New York", "Remote"]
    desired_companies JSONB,  -- ["Google", "Microsoft"]
    min_salary INT,
    job_type TEXT,  -- "internship", "full-time", "part-time"

    -- Auto-apply settings
    auto_apply_enabled BOOLEAN DEFAULT FALSE,
    daily_application_limit INT DEFAULT 10,

    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Job listings (cached)
CREATE TABLE job_listings (
    id SERIAL PRIMARY KEY,
    external_id TEXT UNIQUE,  -- LinkedIn job ID, Indeed job ID
    source TEXT,  -- "linkedin", "indeed", "handshake"

    -- Job details
    title TEXT,
    company TEXT,
    location TEXT,
    salary_min INT,
    salary_max INT,
    job_type TEXT,
    description TEXT,
    requirements TEXT,
    url TEXT,

    -- Application details
    application_method TEXT,  -- "easy_apply", "external", "email"
    application_url TEXT,

    -- Metadata
    posted_date TIMESTAMP,
    scraped_at TIMESTAMP DEFAULT NOW(),
    is_active BOOLEAN DEFAULT TRUE
);

-- Job matches (ML recommendations)
CREATE TABLE job_matches (
    id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(id),
    job_id INT REFERENCES job_listings(id),

    -- Match scoring
    match_score FLOAT,  -- 0-1
    match_reasons JSONB,  -- ["Skills match: 90%", "Location match"]

    -- Status
    status TEXT,  -- "matched", "ignored", "saved", "applied"

    created_at TIMESTAMP DEFAULT NOW()
);

-- Applications
CREATE TABLE job_applications (
    id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(id),
    job_id INT REFERENCES job_listings(id),

    -- Application details
    resume_version TEXT,  -- Which resume was used
    cover_letter TEXT,
    application_date TIMESTAMP DEFAULT NOW(),

    -- Status tracking
    status TEXT,  -- "submitted", "viewed", "interviewing", "rejected", "accepted"
    status_history JSONB,  -- [{"status": "submitted", "date": "..."}]

    -- Follow-up
    last_follow_up TIMESTAMP,
    next_follow_up TIMESTAMP,
    follow_up_count INT DEFAULT 0,

    -- Response
    company_response TEXT,
    interview_date TIMESTAMP,
    offer_amount INT,

    -- Metadata
    applied_manually BOOLEAN DEFAULT FALSE,
    notes TEXT
);

-- Cover letter templates
CREATE TABLE cover_letter_templates (
    id SERIAL PRIMARY KEY,
    user_id INT REFERENCES users(id),
    name TEXT,
    content TEXT,  -- Template with {{company}}, {{role}} placeholders
    is_default BOOLEAN DEFAULT FALSE
);
```

### Implementation Steps

#### Phase 1: Resume & Profile Setup (Week 1)

**Backend:**
```python
# backend/app/api/v1/career.py
from fastapi import APIRouter, UploadFile, File
import PyPDF2
from app.services.resume_parser import ResumeParser

router = APIRouter()

@router.post("/profile/resume/upload")
async def upload_resume(
    file: UploadFile = File(...),
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Upload resume and auto-extract information.
    """
    # Read PDF
    pdf_content = await file.read()

    # Parse resume
    parser = ResumeParser()
    parsed_data = parser.parse(pdf_content)

    # Extract: name, email, phone, skills, education, experience
    profile = UserProfile(
        user_id=current_user.id,
        resume_text=parsed_data['text'],
        skills=parsed_data['skills'],
        education=parsed_data['education'],
        experience=parsed_data['experience']
    )

    db.add(profile)
    await db.commit()

    return profile

@router.post("/profile/preferences")
async def set_job_preferences(
    preferences: JobPreferences,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Set job search preferences.
    """
    # Save desired roles, locations, salary, etc.
    pass
```

**Resume Parser:**
```python
# backend/app/services/resume_parser.py
import spacy
import re
from typing import Dict, List

class ResumeParser:
    def __init__(self):
        self.nlp = spacy.load("en_core_web_sm")

    def parse(self, pdf_content: bytes) -> Dict:
        # Extract text from PDF
        text = self._extract_text(pdf_content)

        # Parse sections
        return {
            'text': text,
            'email': self._extract_email(text),
            'phone': self._extract_phone(text),
            'skills': self._extract_skills(text),
            'education': self._extract_education(text),
            'experience': self._extract_experience(text)
        }

    def _extract_skills(self, text: str) -> List[str]:
        """Extract skills using NLP and keyword matching."""
        # Common tech skills
        skill_keywords = [
            'Python', 'JavaScript', 'React', 'Node.js', 'SQL',
            'Machine Learning', 'Data Analysis', 'AWS', 'Docker',
            'Git', 'Agile', 'Communication', 'Leadership'
        ]

        found_skills = []
        text_lower = text.lower()

        for skill in skill_keywords:
            if skill.lower() in text_lower:
                found_skills.append(skill)

        return found_skills

    def _extract_education(self, text: str) -> List[Dict]:
        """Extract education history."""
        education = []

        # Look for degree patterns
        degree_pattern = r'(Bachelor|Master|PhD|B\.S\.|M\.S\.|MBA)'
        degrees = re.findall(degree_pattern, text, re.IGNORECASE)

        # Look for universities
        # Use NER to find organizations
        doc = self.nlp(text)
        universities = [ent.text for ent in doc.ents if ent.label_ == 'ORG']

        return education

    def _extract_experience(self, text: str) -> List[Dict]:
        """Extract work experience."""
        experience = []

        # Look for date ranges (e.g., "Jan 2020 - Present")
        # Extract company names, roles

        return experience
```

#### Phase 2: Job Scraping (Week 2)

**Job Scraper:**
```python
# backend/app/services/job_scraper.py
from playwright.async_api import async_playwright
from bs4 import BeautifulSoup
import asyncio
from typing import List, Dict

class JobScraper:
    def __init__(self):
        self.playwright = None
        self.browser = None

    async def __aenter__(self):
        self.playwright = await async_playwright().start()
        self.browser = await self.playwright.chromium.launch(headless=True)
        return self

    async def __aexit__(self, *args):
        await self.browser.close()
        await self.playwright.stop()

    async def scrape_linkedin(
        self,
        keywords: str,
        location: str,
        job_type: str = "internship"
    ) -> List[Dict]:
        """
        Scrape LinkedIn jobs.
        """
        page = await self.browser.new_page()

        # Build search URL
        url = f"https://www.linkedin.com/jobs/search/?keywords={keywords}&location={location}&f_TPR=r86400&f_E={job_type}"

        await page.goto(url)
        await page.wait_for_selector('.job-search-card')

        # Extract job cards
        html = await page.content()
        soup = BeautifulSoup(html, 'html.parser')

        jobs = []
        for card in soup.find_all('div', class_='job-search-card'):
            job = {
                'title': card.find('h3').text.strip(),
                'company': card.find('h4').text.strip(),
                'location': card.find('span', class_='job-search-card__location').text.strip(),
                'url': card.find('a')['href'],
                'external_id': self._extract_job_id(card.find('a')['href']),
                'source': 'linkedin'
            }
            jobs.append(job)

        await page.close()
        return jobs

    async def scrape_indeed(
        self,
        keywords: str,
        location: str
    ) -> List[Dict]:
        """
        Scrape Indeed jobs.
        """
        page = await self.browser.new_page()

        url = f"https://www.indeed.com/jobs?q={keywords}&l={location}"
        await page.goto(url)
        await page.wait_for_selector('.jobsearch-ResultsList')

        html = await page.content()
        soup = BeautifulSoup(html, 'html.parser')

        jobs = []
        for card in soup.find_all('div', class_='job_seen_beacon'):
            # Extract job details
            pass

        await page.close()
        return jobs

    async def scrape_handshake(
        self,
        keywords: str,
        school: str
    ) -> List[Dict]:
        """
        Scrape Handshake (requires authentication).
        """
        # Handshake has an API - use that instead
        pass

# Celery task for background scraping
@celery_app.task
async def scrape_jobs_task(user_id: int):
    """
    Background task to scrape jobs for user.
    """
    # Get user preferences
    profile = await get_user_profile(user_id)

    async with JobScraper() as scraper:
        jobs = []

        for role in profile.desired_roles:
            for location in profile.desired_locations:
                # Scrape each job board
                linkedin_jobs = await scraper.scrape_linkedin(role, location)
                indeed_jobs = await scraper.scrape_indeed(role, location)

                jobs.extend(linkedin_jobs)
                jobs.extend(indeed_jobs)

        # Save to database
        await save_jobs(jobs)

        # Match with user profile
        await match_jobs(user_id, jobs)
```

#### Phase 3: Job Matching with AI (Week 2)

**Job Matcher:**
```python
# backend/app/services/job_matcher.py
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

class JobMatcher:
    def __init__(self):
        self.vectorizer = TfidfVectorizer()

    async def match_jobs(
        self,
        user_profile: UserProfile,
        jobs: List[JobListing]
    ) -> List[JobMatch]:
        """
        Match jobs to user profile using NLP.
        """
        matches = []

        # Combine user profile into text
        user_text = self._profile_to_text(user_profile)

        for job in jobs:
            # Combine job details into text
            job_text = f"{job.title} {job.description} {job.requirements}"

            # Calculate similarity
            match_score = self._calculate_similarity(user_text, job_text)

            # Generate match reasons
            reasons = self._generate_match_reasons(
                user_profile,
                job,
                match_score
            )

            # Only save if match score > threshold
            if match_score > 0.6:
                matches.append(JobMatch(
                    user_id=user_profile.user_id,
                    job_id=job.id,
                    match_score=match_score,
                    match_reasons=reasons,
                    status='matched'
                ))

        return matches

    def _calculate_similarity(self, text1: str, text2: str) -> float:
        """Calculate text similarity using TF-IDF."""
        tfidf_matrix = self.vectorizer.fit_transform([text1, text2])
        similarity = cosine_similarity(tfidf_matrix[0:1], tfidf_matrix[1:2])
        return float(similarity[0][0])

    def _generate_match_reasons(
        self,
        profile: UserProfile,
        job: JobListing,
        score: float
    ) -> List[str]:
        """Generate human-readable match reasons."""
        reasons = []

        # Skill match
        user_skills = set(s.lower() for s in profile.skills)
        job_skills = set(self._extract_skills_from_text(job.requirements))
        matching_skills = user_skills & job_skills

        if matching_skills:
            skill_match_pct = len(matching_skills) / len(job_skills) * 100
            reasons.append(f"Skills match: {skill_match_pct:.0f}% ({', '.join(matching_skills)})")

        # Location match
        if job.location in profile.desired_locations:
            reasons.append(f"Preferred location: {job.location}")

        # Company match
        if job.company in profile.desired_companies:
            reasons.append(f"Target company: {job.company}")

        # Salary match
        if job.salary_min and job.salary_min >= profile.min_salary:
            reasons.append(f"Salary meets requirement: ${job.salary_min:,}+")

        return reasons
```

#### Phase 4: Auto-Apply System (Week 3-4)

**Application Engine:**
```python
# backend/app/services/auto_applier.py
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time

class AutoApplier:
    def __init__(self, user_credentials: Dict):
        self.credentials = user_credentials
        self.driver = None

    async def apply_to_job(
        self,
        job: JobListing,
        user_profile: UserProfile
    ) -> bool:
        """
        Auto-apply to a job posting.
        """
        if job.source == 'linkedin' and job.application_method == 'easy_apply':
            return await self._apply_linkedin_easy(job, user_profile)
        elif job.source == 'indeed':
            return await self._apply_indeed(job, user_profile)
        else:
            # Fallback: open URL and notify user
            return False

    async def _apply_linkedin_easy(
        self,
        job: JobListing,
        profile: UserProfile
    ) -> bool:
        """
        Apply via LinkedIn Easy Apply.
        """
        try:
            # Initialize driver
            self.driver = webdriver.Chrome()

            # Login to LinkedIn
            await self._login_linkedin()

            # Navigate to job
            self.driver.get(job.url)
            time.sleep(2)

            # Click "Easy Apply" button
            easy_apply_btn = WebDriverWait(self.driver, 10).until(
                EC.element_to_be_clickable((By.XPATH, "//button[contains(., 'Easy Apply')]"))
            )
            easy_apply_btn.click()

            # Fill out multi-step form
            while True:
                # Check for common fields
                await self._fill_form_fields(profile)

                # Check if this is the last step
                submit_btn = self.driver.find_elements(By.XPATH, "//button[contains(., 'Submit application')]")
                if submit_btn:
                    submit_btn[0].click()
                    break

                # Otherwise, click "Next"
                next_btn = self.driver.find_element(By.XPATH, "//button[contains(., 'Next')]")
                next_btn.click()
                time.sleep(1)

            self.driver.quit()
            return True

        except Exception as e:
            print(f"Application failed: {e}")
            if self.driver:
                self.driver.quit()
            return False

    async def _fill_form_fields(self, profile: UserProfile):
        """Fill common application form fields."""
        # Email
        email_fields = self.driver.find_elements(By.XPATH, "//input[@type='email']")
        if email_fields:
            email_fields[0].send_keys(profile.email)

        # Phone
        phone_fields = self.driver.find_elements(By.XPATH, "//input[@type='tel']")
        if phone_fields:
            phone_fields[0].send_keys(profile.phone)

        # Resume upload
        resume_fields = self.driver.find_elements(By.XPATH, "//input[@type='file']")
        if resume_fields:
            resume_fields[0].send_keys(profile.resume_pdf_path)

        # Cover letter (if textarea found)
        cover_letter_fields = self.driver.find_elements(By.XPATH, "//textarea")
        if cover_letter_fields:
            cover_letter = await self._generate_cover_letter(profile, job)
            cover_letter_fields[0].send_keys(cover_letter)

    async def _login_linkedin(self):
        """Login to LinkedIn."""
        self.driver.get("https://www.linkedin.com/login")

        email_field = self.driver.find_element(By.ID, "username")
        password_field = self.driver.find_element(By.ID, "password")

        email_field.send_keys(self.credentials['linkedin_email'])
        password_field.send_keys(self.credentials['linkedin_password'])

        login_btn = self.driver.find_element(By.XPATH, "//button[@type='submit']")
        login_btn.click()

        time.sleep(3)  # Wait for login

# Celery task
@celery_app.task
async def auto_apply_task(user_id: int):
    """
    Background task to auto-apply to matched jobs.
    """
    # Get user profile and credentials
    profile = await get_user_profile(user_id)
    credentials = await get_user_credentials(user_id)

    # Get matched jobs (not yet applied)
    matches = await get_unapplied_matches(user_id)

    # Sort by match score
    matches.sort(key=lambda m: m.match_score, reverse=True)

    # Apply to top N jobs (respect daily limit)
    applier = AutoApplier(credentials)
    applied_count = 0

    for match in matches[:profile.daily_application_limit]:
        job = await get_job(match.job_id)

        success = await applier.apply_to_job(job, profile)

        if success:
            # Record application
            await create_application(user_id, job.id, profile)
            applied_count += 1

        # Rate limiting (be respectful to job boards)
        await asyncio.sleep(30)  # 30 seconds between applications

    return applied_count
```

#### Phase 5: Cover Letter Generation (Week 3)

**AI Cover Letter Generator:**
```python
# backend/app/services/cover_letter_generator.py
from openai import AsyncOpenAI

class CoverLetterGenerator:
    def __init__(self):
        self.client = AsyncOpenAI()

    async def generate(
        self,
        user_profile: UserProfile,
        job: JobListing,
        template: Optional[str] = None
    ) -> str:
        """
        Generate personalized cover letter using AI.
        """
        prompt = f"""
        Generate a professional cover letter for a job application.

        Candidate Profile:
        - Name: {user_profile.name}
        - Education: {user_profile.education}
        - Experience: {user_profile.experience}
        - Skills: {', '.join(user_profile.skills)}

        Job Details:
        - Company: {job.company}
        - Role: {job.title}
        - Location: {job.location}
        - Requirements: {job.requirements}

        Instructions:
        - Be concise (3-4 paragraphs)
        - Highlight relevant experience and skills
        - Show enthusiasm for the company and role
        - Professional but conversational tone
        - No generic phrases

        Cover Letter:
        """

        response = await self.client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "You are a professional career coach helping students write cover letters."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )

        return response.choices[0].message.content
```

#### Phase 6: Application Tracking (Week 4)

**API Endpoints:**
```python
# backend/app/api/v1/applications.py

@router.get("/applications")
async def list_applications(
    status: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    List all job applications with status.
    """
    query = select(JobApplication).where(JobApplication.user_id == current_user.id)

    if status:
        query = query.where(JobApplication.status == status)

    result = await db.execute(query)
    return result.scalars().all()

@router.patch("/applications/{id}/status")
async def update_application_status(
    id: int,
    status: str,
    notes: Optional[str] = None,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Update application status (e.g., "interviewing", "rejected").
    """
    application = await db.get(JobApplication, id)

    # Update status
    application.status = status

    # Add to history
    history = application.status_history or []
    history.append({
        "status": status,
        "date": datetime.now().isoformat(),
        "notes": notes
    })
    application.status_history = history

    await db.commit()
    return application

@router.post("/applications/{id}/follow-up")
async def send_follow_up(
    id: int,
    current_user: User = Depends(get_current_user),
    db: AsyncSession = Depends(get_db)
):
    """
    Generate and send follow-up email.
    """
    application = await db.get(JobApplication, id)

    # Generate follow-up email
    email_template = f"""
    Subject: Following up on {application.job.title} application

    Dear Hiring Manager,

    I recently applied for the {application.job.title} position at {application.job.company}.
    I'm very excited about this opportunity and wanted to follow up on my application.

    I believe my skills in [X, Y, Z] would be a great fit for this role, and I'd love
    to discuss how I can contribute to your team.

    Thank you for your consideration.

    Best regards,
    {current_user.full_name}
    """

    # Send email (or provide template for user to send)
    return {"email_template": email_template}
```

### Mobile App Screens

**New Screens to Add:**

1. **Career Hub** (new tab)
   - Job recommendations feed
   - Application status dashboard
   - Quick stats (applied, interviewing, offers)

2. **Job Detail Screen**
   - Full job description
   - Match score with reasons
   - "Apply Now" button
   - "Save for Later" button

3. **Application Tracker**
   - Kanban board view (Applied ‚Üí Interviewing ‚Üí Offer)
   - Timeline view
   - Filter by status/company

4. **Profile Setup**
   - Resume upload
   - Skills editor (chips)
   - Job preferences form
   - Auto-apply toggle

5. **Interview Prep**
   - Common interview questions
   - Company research
   - Mock interview with AI

### Legal & Ethical Considerations

**‚ö†Ô∏è IMPORTANT:**

1. **Terms of Service**
   - LinkedIn, Indeed, etc. may prohibit automated applications
   - Risk of account bans
   - Consider: "Assisted apply" instead of "Auto apply"

2. **User Consent**
   - Clear disclosure of automation
   - User must approve each application (or opt-in)
   - Store credentials securely (encrypted)

3. **Rate Limiting**
   - Respect job boards' rate limits
   - Max 10-20 applications per day
   - Add delays between applications

4. **Data Privacy**
   - Secure storage of resumes and credentials
   - GDPR compliance if targeting EU users
   - Clear data deletion policy

### Alternative Approach: Assisted Apply

**Instead of fully automated:**

1. **Job Matching** - AI recommends best-fit jobs
2. **One-Click Prep** - Pre-fill application with user's data
3. **Smart Alerts** - Notify when great match found
4. **Application Helper** - Browser extension that auto-fills forms
5. **Manual Review** - User reviews and clicks "Submit"

This is **safer legally** and gives user control.

### Cost Estimates

**Additional costs for auto-apply:**
- Selenium/Playwright hosting: $10-20/month
- Proxy services (to avoid IP bans): $30-50/month
- AI cover letter generation: $20-100/month
- Storage for resumes: $5-10/month
- **Total additional: $65-180/month**

### MVP Timeline

**Week 1**: Resume upload + parsing
**Week 2**: Job scraping + matching
**Week 3**: Assisted apply (pre-fill forms)
**Week 4**: Application tracking
**Week 5**: Cover letter generator
**Week 6**: Testing + refinement

**Total**: 6 weeks for MVP

---

## üé® Other High-Value Features

Beyond auto-apply, these would make it a "complete assistant":

### Priority 1 (Next 3 months)
1. ‚úÖ Auto-apply system (covered above)
2. Course/degree progress tracker
3. GPA calculator + grade predictor
4. Study timer with Pomodoro
5. Note-taking with AI summarization

### Priority 2 (Months 4-6)
1. AI tutor for homework help
2. Budget tracker
3. Scholarship finder
4. Group project coordinator
5. Campus event calendar

### Priority 3 (Months 7-12)
1. Study group matcher
2. Professor office hours tracker
3. Textbook price comparison
4. Mental health check-ins
5. Career path recommender

---

## üí° Monetization Ideas

If you're building a full assistant:

1. **Freemium Model**
   - Free: 5 auto-applies per month
   - Premium ($9.99/mo): Unlimited applies + AI cover letters
   - Pro ($19.99/mo): All features + priority support

2. **Pay-per-feature**
   - Auto-apply: $4.99/mo
   - AI tutor: $7.99/mo
   - Full suite: $14.99/mo

3. **B2B (University Licensing)**
   - Sell to universities at $5-10/student/year
   - Bulk licensing for entire campus

---

## üöÄ Ready to Implement?

I can start building the auto-apply system right now. Which approach do you prefer?

**Option A**: Full auto-apply (riskier, but more automated)
**Option B**: Assisted apply (safer, user has control)

Let me know and I'll start implementing!
